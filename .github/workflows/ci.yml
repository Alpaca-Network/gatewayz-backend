name: CI Pipeline

on:
  push:
    branches: [main, staging, develop]
  pull_request:
    branches: [main, staging, develop]
    paths:
      - "src/**"
      - "tests/**"
      - "requirements*.txt"
      - "pyproject.toml"
      - ".github/workflows/ci.yml"
  repository_dispatch:
    types: [monorepo-sync]
  workflow_dispatch:

concurrency:
  group: ${{ github.workflow }}-${{ github.ref }}
  cancel-in-progress: true

env:
  PYTHON_VERSION: "3.12"

jobs:
  # Job 1: Linting and Code Quality
  lint:
    name: Code Quality Checks
    runs-on: blacksmith-4vcpu-ubuntu-2404

    steps:
      - name: Checkout code
        uses: actions/checkout@v4
        with:
          fetch-depth: 1

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: ${{ env.PYTHON_VERSION }}
          cache: 'pip'
          cache-dependency-path: |
            requirements*.txt
            pyproject.toml

      # Wheelhouse cache for binary dependencies
      - name: Restore wheelhouse cache
        uses: actions/cache@v4
        with:
          path: .cache/wheels
          key: ${{ runner.os }}-wheels-${{ hashFiles('requirements*.txt', 'pyproject.toml') }}
          restore-keys: |
            ${{ runner.os }}-wheels-

      - name: Build wheels
        run: |
          mkdir -p .cache/wheels
          pip wheel -r requirements.txt -w .cache/wheels
          pip wheel -r requirements-dev.txt -w .cache/wheels

      - name: Install from wheelhouse
        run: |
          pip install --no-index --find-links=.cache/wheels -r requirements.txt
          pip install --no-index --find-links=.cache/wheels ruff black isort mypy

      - name: Cache mypy
        uses: actions/cache@v4
        with:
          path: .mypy_cache
          key: ${{ runner.os }}-mypy-${{ github.sha }}
          restore-keys: |
            ${{ runner.os }}-mypy-

      - name: Run Ruff (Fast Python Linter)
        run: |
          ruff check src/ --output-format=github
        continue-on-error: true

      - name: Check code formatting with Black
        run: |
          black --check src/
        continue-on-error: true

      - name: Check import sorting with isort
        run: |
          isort --check-only src/
        continue-on-error: true

      - name: MyPy type checking
        run: |
          mypy --cache-dir .mypy_cache src
        continue-on-error: true

  # Job 2: Security Checks
  security:
    name: Security Scan
    runs-on: blacksmith-4vcpu-ubuntu-2404

    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: ${{ env.PYTHON_VERSION }}

      - name: Install security tools
        run: |
          pip install bandit safety

      - name: Run Bandit (Security Linter)
        run: |
          bandit -r src/ -f json -o bandit-report.json || true
          bandit -r src/ || true
        continue-on-error: true

      - name: Check for known vulnerabilities in dependencies
        run: |
          safety check --json || true
        continue-on-error: true

  # Job 3: Run Tests (Parallelized with Sharding)
  test:
    name: Run Tests (Shard ${{ matrix.shard }})
    runs-on: blacksmith-4vcpu-ubuntu-2404
    needs: lint

    strategy:
      fail-fast: false
      matrix:
        shard: [1, 2, 3, 4]  # 4-way parallel execution

    steps:
      - name: Checkout code
        uses: actions/checkout@v4
        with:
          fetch-depth: 1

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: ${{ env.PYTHON_VERSION }}
          cache: 'pip'
          cache-dependency-path: |
            requirements*.txt
            pyproject.toml

      # Wheelhouse cache for binary dependencies
      - name: Restore wheelhouse cache
        uses: actions/cache@v4
        with:
          path: .cache/wheels
          key: ${{ runner.os }}-wheels-${{ hashFiles('requirements*.txt', 'pyproject.toml') }}
          restore-keys: |
            ${{ runner.os }}-wheels-

      - name: Install from wheelhouse
        run: |
          pip install --no-index --find-links=.cache/wheels -r requirements.txt
          pip install --no-index --find-links=.cache/wheels pytest pytest-cov pytest-xdist pytest-split

      # Pull down prior test timing data to split by duration
      - name: Restore pytest timings
        uses: actions/download-artifact@v4
        with:
          name: pytest-durations
        continue-on-error: true

      # Restore pytest cache
      - name: Cache pytest
        uses: actions/cache@v4
        with:
          path: .pytest_cache
          key: ${{ runner.os }}-pytest-${{ github.sha }}-${{ matrix.shard }}
          restore-keys: |
            ${{ runner.os }}-pytest-

      - name: Run tests shard ${{ matrix.shard }}
        id: test_run
        env:
          PYTEST_SPLIT_DURATION_FILE: .pytest-split-durations
          # Test environment variables
          SUPABASE_URL: ${{ secrets.SUPABASE_URL || 'https://test.supabase.co' }}
          SUPABASE_KEY: ${{ secrets.SUPABASE_KEY || 'test-key' }}
          OPENROUTER_API_KEY: ${{ secrets.OPENROUTER_API_KEY || 'test-key' }}
          ENCRYPTION_KEY: ${{ secrets.ENCRYPTION_KEY || 'test-encryption-key-32-bytes!' }}
          ADMIN_API_KEY: ${{ secrets.ADMIN_API_KEY || 'test-admin-key' }}
        run: |
          set +e  # Don't exit on failure - we need to capture output
          # Run tests with pytest-xdist (use all cores) and pytest-split (shard across runners)
          # Target: 25% coverage (current baseline)
          # Exclude smoke tests (they require a running server)
          pytest tests/ -v --tb=short \
            -n auto \
            --dist=loadfile \
            --splits 4 --group ${{ matrix.shard }} \
            --cov=src \
            --cov-report=xml \
            --cov-report=term \
            -m "not smoke" 2>&1 | tee test-output-shard-${{ matrix.shard }}.txt

          TEST_EXIT_CODE=$?

          # Check if tests failed
          if [ $TEST_EXIT_CODE -eq 0 ]; then
            echo "‚úÖ Tests passed for shard ${{ matrix.shard }}"
            echo "tests_failed=false" >> $GITHUB_OUTPUT
          else
            echo "‚ùå Tests failed for shard ${{ matrix.shard }}"
            echo "tests_failed=true" >> $GITHUB_OUTPUT
          fi

          exit $TEST_EXIT_CODE

      - name: Save timings for next run
        if: always()
        run: |
          if [ -f .pytest-split-durations ]; then
            echo "Timings saved"
          else
            echo "No timing file generated yet"
          fi
        shell: bash

      - name: Upload timings artifact
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: pytest-durations-${{ matrix.shard }}
          path: .pytest-split-durations
          if-no-files-found: ignore

      - name: Upload test output for Codex
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: test-output-shard-${{ matrix.shard }}
          path: test-output-shard-${{ matrix.shard }}.txt
          if-no-files-found: ignore

      - name: Upload coverage for shard ${{ matrix.shard }}
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: coverage-${{ matrix.shard }}
          path: .coverage
          if-no-files-found: ignore

  # Job 3B: Merge coverage reports
  coverage:
    name: Coverage Report
    runs-on: blacksmith-4vcpu-ubuntu-2404
    needs: test
    if: always()
    outputs:
      has_failures: ${{ steps.check_tests.outputs.has_failures }}

    steps:
      - name: Checkout code
        uses: actions/checkout@v4
        with:
          fetch-depth: 1

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: ${{ env.PYTHON_VERSION }}

      - name: Install coverage tools
        run: |
          pip install coverage pytest-cov

      - name: Download all coverage artifacts
        uses: actions/download-artifact@v4
        with:
          pattern: coverage-*
          path: coverage-artifacts

      - name: Merge test output files
        if: always()
        run: |
          # Consolidate all test output from shards
          if ls test-output-shard-*.txt 2>/dev/null; then
            cat test-output-shard-*.txt > all-test-output.txt
            echo "Test outputs merged successfully"
          fi

      - name: Download test outputs
        if: always()
        uses: actions/download-artifact@v4
        with:
          pattern: test-output-shard-*
          merge-multiple: true

      - name: Check for test failures and consolidate
        id: check_tests
        if: always()
        run: |
          set +e
          # Consolidate all test outputs
          cat test-output-shard-*.txt > all-test-output.txt 2>/dev/null || echo "No test outputs to merge"

          # Check if any tests failed
          if grep -q "FAILED\|ERROR" all-test-output.txt 2>/dev/null; then
            echo "has_failures=true" >> $GITHUB_OUTPUT
            echo "‚ùå Test failures detected - Codex will attempt fixes"
          else
            echo "has_failures=false" >> $GITHUB_OUTPUT
            echo "‚úÖ No test failures detected"
          fi

      - name: Merge coverage reports
        run: |
          # Each artifact is downloaded to coverage-artifacts/<artifact-name>/.coverage
          # We need to rename them to avoid conflicts during combine
          echo "üìä Merging coverage from all shards..."

          # Create a directory for all coverage files
          mkdir -p coverage-data

          # Copy and rename each .coverage file from the downloaded artifacts
          count=1
          for artifact_dir in coverage-artifacts/coverage-*; do
            if [ -d "$artifact_dir" ] && [ -f "$artifact_dir/.coverage" ]; then
              echo "Found coverage file in $artifact_dir"
              cp "$artifact_dir/.coverage" "coverage-data/.coverage.shard-$count"
              count=$((count + 1))
            fi
          done

          # List what we found
          echo "Coverage files to merge:"
          ls -la coverage-data/ || echo "‚ö†Ô∏è No coverage files found"

          # Move coverage files to current directory for combining
          if [ -d coverage-data ] && [ "$(ls -A coverage-data)" ]; then
            mv coverage-data/.coverage.* . 2>/dev/null

            # Combine all coverage files into one .coverage file
            echo "Combining coverage files..."
            coverage combine --keep || echo "‚ö†Ô∏è Coverage combine had warnings"

            # Generate XML report from combined coverage
            echo "Generating coverage XML..."
            coverage xml -o coverage.xml || echo "‚ö†Ô∏è Coverage XML generation had warnings"

            # Display coverage report
            echo "Coverage Summary:"
            coverage report --fail-under=25 || echo "‚ö†Ô∏è Coverage below 25% threshold"

            # Verify the coverage.xml was created
            if [ -f coverage.xml ]; then
              echo "‚úÖ Coverage XML generated successfully"
              ls -lh coverage.xml
            else
              echo "‚ùå Error: coverage.xml was not generated"
            fi
          else
            echo "‚ùå No coverage files found to merge"
          fi

      - name: Check coverage progress
        if: always()
        run: |
          echo "üìä Coverage Progress Tracker"
          echo "Current minimum: 25%"
          echo "Next milestone: 35% (Target: Month 2)"
          echo "Phase 3A Goal: 40% (Add auth, users, api_keys, db_security tests)"
          echo "Phase 3 Final Goal: 90% (Complete test coverage)"
          echo ""
          echo "Run locally: pytest tests/ --cov=src --cov-report=html"

      - name: Upload consolidated test output
        if: always() && steps.check_tests.outputs.has_failures == 'true'
        uses: actions/upload-artifact@v4
        with:
          name: test-failures
          path: all-test-output.txt
          if-no-files-found: ignore

      - name: Upload merged coverage to Codecov
        if: always()
        uses: codecov/codecov-action@v4
        with:
          token: ${{ secrets.CODECOV_TOKEN }}
          file: ./coverage.xml
          flags: unittests
          name: codecov-gatewayz
          fail_ci_if_error: false
        continue-on-error: true

      # Merge pytest timing data for next run
      - name: Download all timing artifacts
        uses: actions/download-artifact@v4
        with:
          pattern: pytest-durations-*
          merge-multiple: true
        continue-on-error: true

      - name: Upload merged timings
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: pytest-durations
          path: .pytest-split-durations
          if-no-files-found: ignore

  # Job 4: Build Check
  build:
    name: Build Verification
    runs-on: blacksmith-4vcpu-ubuntu-2404
    needs: [lint, coverage]  # Only run if lint and tests pass

    steps:
      - name: Checkout code
        uses: actions/checkout@v4
        with:
          fetch-depth: 1

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: ${{ env.PYTHON_VERSION }}
          cache: 'pip'
          cache-dependency-path: |
            requirements*.txt
            pyproject.toml

      # Fresh dependency resolution check (simulates Railway/Docker build)
      # This catches dependency conflicts that would fail on Railway
      - name: Verify dependency resolution (Railway build simulation)
        shell: bash
        run: |
          set -euo pipefail  # Exit on error, undefined vars, and pipe failures

          echo "üîç Simulating fresh Railway/Docker dependency resolution..."
          echo "This catches conflicts that would fail deployment builds."
          echo ""

          # Create a fresh virtual environment using the Python version from setup-python
          # Use python3 as fallback for compatibility
          python${{ env.PYTHON_VERSION }} -m venv .railway-test-venv || python3 -m venv .railway-test-venv
          source .railway-test-venv/bin/activate

          # Upgrade pip to match Railway's build environment
          pip install --upgrade pip

          # Attempt fresh install - this will fail if there are dependency conflicts
          # Using --dry-run first to check resolution without downloading
          echo "üì¶ Checking dependency resolution..."
          if ! pip install --dry-run -r requirements.txt 2>&1 | tee dependency-check.log; then
            echo ""
            echo "‚ùå DEPENDENCY CONFLICT DETECTED"
            echo "This would cause Railway build to fail!"
            echo ""
            echo "=== Conflict Details ==="
            grep -A5 "ERROR\|conflict" dependency-check.log || cat dependency-check.log
            echo ""
            echo "Fix: Update requirements.txt to resolve version conflicts"
            deactivate
            rm -rf .railway-test-venv
            exit 1
          fi

          # Actually install to verify (catches issues --dry-run might miss)
          echo "üì¶ Performing full dependency installation..."
          if ! pip install -r requirements.txt 2>&1 | tee install.log; then
            echo ""
            echo "‚ùå DEPENDENCY INSTALLATION FAILED"
            echo "This would cause Railway build to fail!"
            grep -A5 "ERROR\|conflict" install.log || tail -50 install.log
            deactivate
            rm -rf .railway-test-venv
            exit 1
          fi

          # Verify no broken dependencies
          echo "üîç Checking for broken dependencies..."
          if ! pip check 2>&1 | tee pip-check.log; then
            echo ""
            echo "‚ö†Ô∏è BROKEN DEPENDENCIES DETECTED"
            cat pip-check.log
            deactivate
            rm -rf .railway-test-venv
            exit 1
          fi

          echo "‚úÖ All dependencies resolve correctly (Railway build will succeed)"
          deactivate
          rm -rf .railway-test-venv

      # Wheelhouse cache for binary dependencies
      - name: Restore wheelhouse cache
        uses: actions/cache@v4
        with:
          path: .cache/wheels
          key: ${{ runner.os }}-wheels-${{ hashFiles('requirements*.txt', 'pyproject.toml') }}
          restore-keys: |
            ${{ runner.os }}-wheels-

      - name: Install from wheelhouse
        run: |
          pip install --no-index --find-links=.cache/wheels -r requirements.txt

      - name: Test application startup
        run: |
          # Quick startup test (don't start server, just import)
          python -c "from src.main import app; print('‚úÖ App imports successfully')"

      - name: Verify Railway config
        run: |
          # Check Railway config files exist
          test -f railway.json && echo "‚úÖ railway.json exists"
          test -f railway.toml && echo "‚úÖ railway.toml exists"
          test -f nixpacks.toml && echo "‚úÖ nixpacks.toml exists"
          test -f start.sh && echo "‚úÖ start.sh exists"
          echo "‚úÖ Railway deployment config verified"

  # Job 5: Deployment Ready Check
  deployment-check:
    name: Deployment Ready
    runs-on: blacksmith-4vcpu-ubuntu-2404
    needs: [lint, security, coverage, build]
    if: github.event_name == 'push'

    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: All checks passed ‚úÖ
        run: |
          echo "üéâ All CI checks passed!"
          echo "‚úÖ Code quality: PASSED"
          echo "‚úÖ Security: PASSED"
          echo "‚úÖ Tests: PASSED"
          echo "‚úÖ Build: PASSED"
          echo ""
          echo "üöÄ Ready for deployment to Railway"
          echo "Branch: ${{ github.ref_name }}"

      - name: Comment on PR (if applicable)
        if: github.event_name == 'pull_request'
        uses: actions/github-script@v7
        with:
          script: |
            github.rest.issues.createComment({
              issue_number: context.issue.number,
              owner: context.repo.owner,
              repo: context.repo.repo,
              body: '‚úÖ All CI checks passed! This PR is ready to merge and deploy.'
            })

  # Job 5B: Trigger Cursor CLI Auto-Fix
  # (Automatically triggers via workflow_run, but can also be manually dispatched)
  trigger-cursor-auto-fix:
    name: Notify Cursor Auto-Fix
    runs-on: blacksmith-4vcpu-ubuntu-2404
    # Depends on critical jobs and runs if any failed
    needs: [lint, security, test, coverage, build]
    if: failure()

    steps:
      - name: Log CI failure detected
        run: |
          echo "üìå CI failure detected - Cursor auto-fix workflow will be triggered"
          echo ""
          echo "The 'fix-ci-cursor' workflow will:"
          echo "  ‚úì Detect the failure"
          echo "  ‚úì Analyze root cause"
          echo "  ‚úì Apply targeted fixes"
          echo "  ‚úì Commit directly to PR branch"
          echo ""
          echo "üîó Workflow: .github/workflows/fix-ci-cursor.yml"

  # Job 6: Railway Deployment Notification
  notify-deployment:
    name: Notify Deployment
    runs-on: blacksmith-4vcpu-ubuntu-2404
    needs: [deployment-check]
    if: github.event_name == 'push' && (github.ref == 'refs/heads/main' || github.ref == 'refs/heads/staging')

    steps:
      - name: Deployment notification
        run: |
          if [ "${{ github.ref_name }}" == "main" ]; then
            echo "üöÄ Deploying to PRODUCTION via Railway..."
          elif [ "${{ github.ref_name }}" == "staging" ]; then
            echo "üöÄ Deploying to STAGING via Railway..."
          fi
