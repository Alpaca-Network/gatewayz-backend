name: Schema Sync Check

# This workflow ensures test environments stay in sync with production schema
# It runs:
# 1. On every PR that touches migration files
# 2. On manual trigger for ad-hoc validation
# 3. Nightly to catch any schema drift

on:
  pull_request:
    branches: [main, staging]
    paths:
      - 'supabase/migrations/**'
      - 'supabase/seed.sql'
      - 'scripts/database/**'
  push:
    branches: [main]
    paths:
      - 'supabase/migrations/**'
  schedule:
    # Run nightly at 2 AM UTC to catch any drift
    - cron: '0 2 * * *'
  workflow_dispatch:
    inputs:
      validate_production:
        description: 'Validate against production schema'
        required: false
        default: false
        type: boolean

concurrency:
  group: schema-sync-${{ github.ref }}
  cancel-in-progress: true

env:
  PYTHON_VERSION: '3.12'

jobs:
  # Job 1: Validate migration files
  validate-migrations:
    name: Validate Migration Files
    runs-on: blacksmith-4vcpu-ubuntu-2404

    steps:
      - name: Checkout code
        uses: actions/checkout@v4
        with:
          fetch-depth: 0  # Full history for comparing branches

      - name: Check migration file naming
        run: |
          echo "Checking migration file naming conventions..."
          INVALID_FILES=""

          # Check if any migration files exist
          shopt -s nullglob
          files=(supabase/migrations/*.sql)
          shopt -u nullglob

          if [ ${#files[@]} -eq 0 ]; then
            echo "No migration files found - skipping validation"
            exit 0
          fi

          for file in "${files[@]}"; do
            filename=$(basename "$file")
            # Expected format: YYYYMMDDHHMMSS_description.sql
            if ! [[ "$filename" =~ ^[0-9]{14}_[a-z0-9_]+\.sql$ ]]; then
              echo "❌ Invalid migration filename: $filename"
              echo "   Expected format: YYYYMMDDHHMMSS_description.sql"
              INVALID_FILES="$INVALID_FILES $filename"
            fi
          done

          if [ -n "$INVALID_FILES" ]; then
            echo "::error::Invalid migration filenames found"
            exit 1
          fi
          echo "✅ All migration filenames are valid"

      - name: Check for migration conflicts
        if: github.event_name == 'pull_request'
        run: |
          echo "Checking for migration timestamp conflicts..."

          # Get migrations added in this PR
          BASE_SHA=${{ github.event.pull_request.base.sha }}
          HEAD_SHA=${{ github.event.pull_request.head.sha }}

          NEW_MIGRATIONS=$(git diff --name-only --diff-filter=A $BASE_SHA $HEAD_SHA -- 'supabase/migrations/*.sql' || true)

          if [ -z "$NEW_MIGRATIONS" ]; then
            echo "No new migrations in this PR"
            exit 0
          fi

          echo "New migrations in this PR:"
          echo "$NEW_MIGRATIONS"

          # Check if any timestamps conflict with existing migrations on main
          CONFLICTS=""
          for migration in $NEW_MIGRATIONS; do
            timestamp=$(basename "$migration" | cut -d'_' -f1)
            # Check if this timestamp exists on main branch
            EXISTING=$(git ls-tree -r origin/main --name-only -- 'supabase/migrations/' | grep "^supabase/migrations/${timestamp}_" || true)
            if [ -n "$EXISTING" ]; then
              echo "❌ Timestamp conflict: $migration conflicts with $EXISTING"
              CONFLICTS="$CONFLICTS\n$migration"
            fi
          done

          if [ -n "$CONFLICTS" ]; then
            echo "::error::Migration timestamp conflicts detected. Please use a new timestamp."
            exit 1
          fi
          echo "✅ No migration conflicts detected"

      - name: Validate SQL syntax
        run: |
          echo "Validating SQL syntax..."

          # Check if any migration files exist
          shopt -s nullglob
          files=(supabase/migrations/*.sql)
          shopt -u nullglob

          if [ ${#files[@]} -eq 0 ]; then
            echo "No migration files found - skipping validation"
            exit 0
          fi

          # Check for common SQL errors
          ERRORS=""
          for file in "${files[@]}"; do
            # Check for missing semicolons at end of statements
            if grep -P '^\s*(CREATE|ALTER|DROP|INSERT|UPDATE|DELETE|GRANT|REVOKE)\s' "$file" | grep -v ';$' | grep -v '^\s*--' > /dev/null; then
              echo "⚠️  Possible missing semicolon in: $file"
            fi

            # Check for common typos
            if grep -iE '\b(CREAT|SELCT|DELTE|UDPATE|INSRT)\b' "$file"; then
              echo "❌ Possible typo found in: $file"
              ERRORS="$ERRORS $file"
            fi

            # Check for dangerous operations without IF EXISTS
            if grep -E '^\s*DROP\s+(TABLE|INDEX|FUNCTION)\s+[^I]' "$file" | grep -v 'IF EXISTS' > /dev/null; then
              echo "⚠️  DROP without IF EXISTS in: $file"
            fi
          done

          if [ -n "$ERRORS" ]; then
            echo "::error::SQL validation errors found"
            exit 1
          fi
          echo "✅ SQL syntax validation passed"

  # Job 2: Test schema against local Supabase
  test-local-schema:
    name: Test Schema (Local Supabase)
    runs-on: blacksmith-4vcpu-ubuntu-2404
    needs: validate-migrations

    services:
      # Note: Supabase local requires Docker, we'll use the CLI instead

    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Setup Supabase CLI
        uses: supabase/setup-cli@v1
        with:
          version: latest

      - name: Start Supabase
        run: |
          supabase start -x realtime,storage,imgproxy,edge-runtime,logflare,vector,supavisor

      - name: Get Supabase status
        id: supabase
        run: |
          # Get connection details
          STATUS=$(supabase status --output json)
          echo "ANON_KEY=$(echo $STATUS | jq -r '.ANON_KEY')" >> $GITHUB_OUTPUT
          echo "SERVICE_KEY=$(echo $STATUS | jq -r '.SERVICE_ROLE_KEY')" >> $GITHUB_OUTPUT
          echo "API_URL=$(echo $STATUS | jq -r '.API_URL')" >> $GITHUB_OUTPUT

      - name: Apply migrations
        run: |
          echo "Applying migrations..."
          set -o pipefail  # Ensure pipeline returns the exit code of the first failed command
          set +e  # Don't exit on error, we'll check the exit code
          supabase db reset --debug 2>&1 | tee migration_output.txt
          EXIT_CODE=${PIPESTATUS[0]}  # Get exit code of supabase command, not tee
          set -e

          # Check exit code first - this is the most reliable indicator
          if [ $EXIT_CODE -ne 0 ]; then
            echo "::error::Migration command failed with exit code $EXIT_CODE"
            exit 1
          fi

          # Check for actual error patterns (not just the word "error" anywhere)
          # Look for PostgreSQL error patterns and Supabase CLI error messages
          if grep -E "(ERROR:|FATAL:|PANIC:|error applying migration|migration failed|syntax error)" migration_output.txt; then
            echo "::error::Migration errors detected in output"
            exit 1
          fi
          echo "✅ Migrations applied successfully"

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: ${{ env.PYTHON_VERSION }}
          cache: 'pip'

      - name: Install dependencies
        run: |
          pip install supabase

      - name: Validate schema
        env:
          SUPABASE_URL: ${{ steps.supabase.outputs.API_URL }}
          SUPABASE_SERVICE_KEY: ${{ steps.supabase.outputs.SERVICE_KEY }}
        run: |
          python scripts/database/validate_schema_sync.py --ci --verbose

      - name: Run seed script
        env:
          SUPABASE_URL: ${{ steps.supabase.outputs.API_URL }}
          SUPABASE_SERVICE_KEY: ${{ steps.supabase.outputs.SERVICE_KEY }}
        run: |
          echo "Running seed script to verify data can be inserted..."
          python scripts/database/seed_test_data.py --users 5 --api-keys 2

      - name: Generate schema snapshot
        env:
          SUPABASE_URL: ${{ steps.supabase.outputs.API_URL }}
          SUPABASE_SERVICE_KEY: ${{ steps.supabase.outputs.SERVICE_KEY }}
        run: |
          python scripts/database/validate_schema_sync.py --snapshot --snapshot-file schema_snapshot.json

      - name: Upload schema snapshot
        uses: actions/upload-artifact@v4
        with:
          name: schema-snapshot
          path: schema_snapshot.json
          retention-days: 30

      - name: Stop Supabase
        if: always()
        run: supabase stop

  # Job 3: Compare against production (optional, requires secrets)
  compare-production:
    name: Compare with Production
    runs-on: blacksmith-4vcpu-ubuntu-2404
    needs: test-local-schema
    if: |
      github.event_name == 'schedule' ||
      (github.event_name == 'workflow_dispatch' && inputs.validate_production) ||
      (github.event_name == 'push' && github.ref == 'refs/heads/main')

    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: ${{ env.PYTHON_VERSION }}
          cache: 'pip'

      - name: Install dependencies
        run: pip install supabase

      - name: Download schema snapshot
        uses: actions/download-artifact@v4
        with:
          name: schema-snapshot

      - name: Compare schemas
        if: ${{ secrets.PROD_SUPABASE_URL && secrets.PROD_SUPABASE_SERVICE_KEY }}
        env:
          SUPABASE_URL: ${{ secrets.PROD_SUPABASE_URL }}
          SUPABASE_SERVICE_KEY: ${{ secrets.PROD_SUPABASE_SERVICE_KEY }}
        run: |
          echo "Comparing production schema against local schema snapshot..."
          # Generate production schema snapshot
          python scripts/database/validate_schema_sync.py --snapshot --snapshot-file prod_snapshot.json

          echo "Comparing production snapshot with local snapshot..."
          # Compare production against the local snapshot we generated earlier
          python scripts/database/validate_schema_sync.py \
            --compare-snapshot schema_snapshot.json \
            --ci --verbose || {
            echo "::warning::Schema differences detected between test and production"
            # Don't fail on differences, just warn
            exit 0
          }

      - name: Skip production comparison
        if: ${{ !secrets.PROD_SUPABASE_URL || !secrets.PROD_SUPABASE_SERVICE_KEY }}
        run: |
          echo "::notice::Skipping production comparison - secrets not configured"
          echo "To enable, set PROD_SUPABASE_URL and PROD_SUPABASE_SERVICE_KEY secrets"

  # Job 4: Post results to PR
  report:
    name: Report Results
    runs-on: blacksmith-4vcpu-ubuntu-2404
    needs: [validate-migrations, test-local-schema]
    if: github.event_name == 'pull_request'

    steps:
      - name: Download schema snapshot
        uses: actions/download-artifact@v4
        with:
          name: schema-snapshot
        continue-on-error: true

      - name: Comment on PR
        uses: actions/github-script@v7
        with:
          script: |
            const fs = require('fs');

            let schemaInfo = "Schema snapshot not available";
            try {
              const snapshot = JSON.parse(fs.readFileSync('schema_snapshot.json', 'utf8'));
              const tableCount = Object.keys(snapshot.tables || {}).length;
              const functionCount = (snapshot.functions || []).length;
              const indexCount = (snapshot.indexes || []).length;
              schemaInfo = `- Tables: ${tableCount}\n- Functions: ${functionCount}\n- Indexes: ${indexCount}`;
            } catch (e) {
              console.log('Could not read schema snapshot:', e.message);
            }

            const body = `## Schema Sync Check Results ✅

            All schema validation checks passed!

            ### Schema Summary
            ${schemaInfo}

            ### Checks Performed
            - ✅ Migration file naming convention
            - ✅ Migration timestamp conflicts
            - ✅ SQL syntax validation
            - ✅ Schema applied successfully to local Supabase
            - ✅ Schema validation against expected tables
            - ✅ Seed data inserted successfully

            ---
            *This check runs automatically on PRs that modify database migrations.*
            `;

            // Find existing comment
            const { data: comments } = await github.rest.issues.listComments({
              owner: context.repo.owner,
              repo: context.repo.repo,
              issue_number: context.issue.number,
            });

            const botComment = comments.find(c =>
              c.user.type === 'Bot' && c.body.includes('Schema Sync Check Results')
            );

            if (botComment) {
              await github.rest.issues.updateComment({
                owner: context.repo.owner,
                repo: context.repo.repo,
                comment_id: botComment.id,
                body: body
              });
            } else {
              await github.rest.issues.createComment({
                owner: context.repo.owner,
                repo: context.repo.repo,
                issue_number: context.issue.number,
                body: body
              });
            }
