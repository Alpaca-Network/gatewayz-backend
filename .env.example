# Environment Configuration
# Options: development, staging, production
APP_ENV=development

# Supabase
SUPABASE_URL=https://your-project.supabase.co
SUPABASE_KEY=your-supabase-anon-key
# Optional: direct Postgres connection string used for schema cache refresh fallback
# Format: postgresql://USER:PASSWORD@HOST:PORT/postgres?sslmode=require
SUPABASE_DB_DSN=postgresql://postgres:password@db.supabase.co:5432/postgres

# Stripe Keys
STRIPE_SECRET_KEY=sk_qwer...
STRIPE_WEBHOOK_SECRET=whsec_qwer...
STRIPE_PUBLISHABLE_KEY=pk_qwer...

# Open Router Keys
OPENROUTER_API_KEY=sk-or-v1-...
OPENROUTER_SITE_URL=https://your-site.com
OPENROUTER_SITE_NAME=Openrouter AI Gateway

# Frontend URL (for CORS and redirects)
FRONTEND_URL=http://localhost:3000

# Optional - Additional Provider API Keys
FEATHERLESS_API_KEY=your-featherless-api-key
CHUTES_API_KEY=your-chutes-api-key
FIREWORKS_API_KEY=your-fireworks-api-key
TOGETHER_API_KEY=your-together-api-key
GROQ_API_KEY=your-groq-api-key
AIMO_API_KEY=your-aimo-api-key
NEAR_API_KEY=your-near-api-key
XAI_API_KEY=your-xai-api-key
NEBIUS_API_KEY=your-nebius-api-key
CEREBRAS_API_KEY=your-cerebras-api-key
NOVITA_API_KEY=your-novita-api-key
HUG_API_KEY=your-huggingface-api-key
FAL_API_KEY=your-fal-api-key
RESEMBLE_API_KEY=your-resemble-api-key  # For Chatterbox TTS (optional, uses local inference if not set)
ANANNAS_API_KEY=your-anannas-api-key
AIHUBMIX_API_KEY=sk-your-aihubmix-api-key
AIHUBMIX_APP_CODE=your-6-digit-referral-code

# Nosana GPU Computing Network Configuration
# Distributed GPU infrastructure for AI workloads
# Get API key from: https://dashboard.nosana.com
# Documentation: https://learn.nosana.com/api
NOSANA_API_KEY=nos_xxx_your_api_key
NOSANA_BASE_URL=https://dashboard.k8s.prd.nos.ci/api

# Z.AI Configuration (Zhipu AI - GLM models)
# Z.AI provides the GLM family of models (GLM-4.7, GLM-4.5-Air, etc.)
# Get API key from: https://z.ai/manage-apikey/apikey-list
# Documentation: https://docs.z.ai
ZAI_API_KEY=your-zai-api-key

# Helicone AI Gateway Configuration (for LLM observability & logging)
# Get your API key from: https://helicone.ai/developer
# Helicone provides request logging, caching, rate limiting, and analytics
# Documentation: https://docs.helicone.ai/getting-started/quick-start
HELICONE_API_KEY=sk-helicone-your-api-key

# Optional - Additional API Keys
DEEPINFRA_API_KEY=your-deepinfra-key

# Google Vertex AI Configuration (for Stability Diffusion v1.5 image generation)
GOOGLE_CLOUD_PROJECT
GOOGLE_VERTEX_CREDENTIALS_JSON
GOOGLE_PROJECT_ID=gatewayz-468519
GOOGLE_VERTEX_LOCATION=us-central1
GOOGLE_VERTEX_ENDPOINT_ID=6072619212881264640
GOOGLE_APPLICATION_CREDENTIALS=/path/to/service-account-key.json
GOOGLE_VERTEX_SERVICE_ACCOUNT

# Analytics (optional - for server-side analytics integration)
# Statsig - Get from https://console.statsig.com -> Project Settings -> API Keys -> Server Secret Key
STATSIG_SERVER_SECRET_KEY=secret-your-server-secret-key

# PostHog - Get from https://app.posthog.com/project/settings -> Project API Key
POSTHOG_API_KEY=phc_your-project-api-key
POSTHOG_HOST=https://us.i.posthog.com  # or https://eu.i.posthog.com for EU, or your self-hosted URL
POSTHOG_DEBUG=false  # Set to true for debug logging

# Braintrust - AI observability and evaluation platform
BRAINTRUST_API_KEY=sk-your-braintrust-api-key

# ==================== Observability Configuration ====================

# OpenTelemetry Service Configuration
OTEL_SERVICE_NAME=gatewayz-api

# Tempo Configuration (Distributed Tracing)
# Set to true to enable OpenTelemetry tracing to Tempo
TEMPO_ENABLED=false
# For Railway internal networking (recommended):
TEMPO_OTLP_HTTP_ENDPOINT=http://tempo.railway.internal:4318
# For external services or public URLs:
# TEMPO_OTLP_HTTP_ENDPOINT=https://tempo-production-xxxx.up.railway.app:4318

# Grafana Loki Configuration (Structured Logging)
# Set to true to enable log shipping to Loki
LOKI_ENABLED=false
# For Railway internal networking (recommended):
LOKI_PUSH_URL=http://loki.railway.internal:3100/loki/api/v1/push
# For external services or public URLs:
# LOKI_PUSH_URL=https://loki-production-xxxx.up.railway.app/loki/api/v1/push
# Optional override: defaults to the push URL host with /loki/api/v1/query_range
# LOKI_QUERY_URL=http://loki.railway.internal:3100/loki/api/v1/query_range

# Prometheus Configuration (Metrics)
PROMETHEUS_ENABLED=true
PROMETHEUS_SCRAPE_ENABLED=true
# Prometheus scrapes metrics from /metrics endpoint automatically

# Sentry Configuration (Error Monitoring & Release Tracking)
SENTRY_DSN=https://your-sentry-dsn@sentry.io/your-project-id
SENTRY_ENABLED=true
SENTRY_ENVIRONMENT=production
SENTRY_RELEASE=2.0.3
SENTRY_TRACES_SAMPLE_RATE=1.0  # Capture 100% of transactions (adjust for high-traffic)
SENTRY_PROFILES_SAMPLE_RATE=0.1  # Capture 10% of profiling data

# Grafana Cloud Configuration (Managed Observability Stack)
# Get credentials from: https://grafana.com/orgs/your-org/stacks
GRAFANA_CLOUD_ENABLED=false

# Grafana Cloud Prometheus (Metrics Remote Write)
# Remote write URL: https://prometheus-prod-xx-prod-us-central-x.grafana.net/api/prom/push
GRAFANA_PROMETHEUS_REMOTE_WRITE_URL=https://prometheus-prod-xx-prod-us-central-x.grafana.net/api/prom/push
GRAFANA_PROMETHEUS_USERNAME=123456  # Your Grafana Cloud instance ID
GRAFANA_PROMETHEUS_API_KEY=glc_your-grafana-cloud-api-key

# Grafana Cloud Loki (Logs) - Override default Loki settings
# If using Grafana Cloud, set these instead of the Railway Loki settings above
# LOKI_PUSH_URL=https://logs-prod-xx.grafana.net/loki/api/v1/push
# GRAFANA_LOKI_USERNAME=123456
# GRAFANA_LOKI_API_KEY=glc_your-grafana-cloud-api-key

# Grafana Cloud Tempo (Traces) - Override default Tempo settings
# If using Grafana Cloud, set these instead of the Railway Tempo settings above
# TEMPO_OTLP_HTTP_ENDPOINT=https://tempo-prod-xx-prod-us-central-x.grafana.net/tempo
# GRAFANA_TEMPO_USERNAME=123456
# GRAFANA_TEMPO_API_KEY=glc_your-grafana-cloud-api-key

# ==================== OpenLLMetry / Traceloop SDK Configuration ====================
# Traceloop SDK provides automatic instrumentation of LLM SDK calls (OpenAI, Anthropic, etc.)
# Uses standardized gen_ai.* semantic conventions for observability tools
# Documentation: https://traceloop.com/docs/openllmetry/getting-started/python

# Enable/disable OpenLLMetry SDK (defaults to TEMPO_ENABLED value)
OPENLLMETRY_ENABLED=true

# OTLP Endpoint for Traceloop (optional - defaults to TEMPO_OTLP_HTTP_ENDPOINT)
# If using Traceloop Cloud, use their provided endpoint
# TRACELOOP_BASE_URL=https://api.traceloop.com

# Authentication headers for OTLP endpoint (JSON format)
# Example for Grafana Cloud: {"Authorization": "Basic <base64_encoded_user:api_key>"}
# TRACELOOP_HEADERS={"Authorization": "Basic YOUR_BASE64_AUTH"}

# Traceloop Cloud API Key (optional - only if using Traceloop Cloud)
# Get your API key from: https://app.traceloop.com/settings/api-keys
# TRACELOOP_API_KEY=tl_your-traceloop-api-key

# Redis Configuration (for real-time metrics and rate limiting)
# For local development: redis://localhost:6379
# For Upstash (with TLS): rediss://default:YOUR_TOKEN@YOUR_ENDPOINT.upstash.io:6379
# For Railway/Cloud: Use RAILWAY_SERVICE_REDIS_URL or REDIS_URL
REDIS_URL=redis://localhost:6379
REDIS_ENABLED=true
REDIS_MAX_CONNECTIONS=50
REDIS_SOCKET_TIMEOUT=5
REDIS_SOCKET_CONNECT_TIMEOUT=5

# Optional: For Upstash Redis (REST API alternative)
# UPSTASH_REDIS_REST_URL=https://your-endpoint.upstash.io
# UPSTASH_REDIS_REST_TOKEN=your-token-here

# Metrics Aggregation Configuration
# Enable hourly aggregation job to transfer Redis metrics to database
METRICS_AGGREGATION_ENABLED=true
METRICS_AGGREGATION_INTERVAL_MINUTES=60
# Retention: How long to keep Redis metrics before cleanup (hours)
METRICS_REDIS_RETENTION_HOURS=2

# ==================== API Key Security Configuration ====================
# REQUIRED for API key creation. Generate with:
#   python -c "import secrets; print('KEY_HASH_SALT=' + secrets.token_hex(32))"
KEY_HASH_SALT=your-32-character-random-hex-string

# OPTIONAL - API Key Encryption (for additional security)
# If not set, API keys are stored encrypted by default but can fall back to plaintext
# To enable: Generate with:
#   from cryptography.fernet import Fernet; print(Fernet.generate_key().decode())
KEY_VERSION=1
KEYRING_1=your-base64-encoded-fernet-key

# ==================== Admin API Key ====================
# REQUIRED for admin endpoints (/admin/*). Generate a secure key with:
#   python3 -c "import secrets; print('sk_admin_live_' + secrets.token_urlsafe(32))"
# Keep this key secret and rotate it periodically. Use different keys for different environments.
ADMIN_API_KEY=sk_admin_live_your-secure-admin-key-here

# ==================== Model Sync Configuration ====================
# The system uses database-first architecture for model catalog:
# - Catalog endpoints read from database (via Redis cache)
# - Scheduled background sync keeps database fresh
# - No provider API calls in the request path (faster, more reliable)

# Enable scheduled background sync of models from provider APIs to database
# Default: true (sync runs automatically every 30 minutes)
ENABLE_SCHEDULED_MODEL_SYNC=true

# How often to sync models from provider APIs (in minutes)
# Recommended: 15-30 minutes for balance between freshness and API rate limits
# Lower values = fresher data but more API calls
# Higher values = less API load but potentially stale data
MODEL_SYNC_INTERVAL_MINUTES=30
